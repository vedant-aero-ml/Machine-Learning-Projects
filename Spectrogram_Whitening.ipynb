{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee535282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "from scipy import linalg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a41a1e",
   "metadata": {},
   "source": [
    "# Function which inputs path of the file and returns spectrogram, after slicing from the FFT of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c12dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram(path):\n",
    "    sample_rate, data = wavfile.read(path) # Reading the file and decomposing into sample rate and amplitude vector\n",
    "    \n",
    "    # Defining Hamming window particulars\n",
    "    window = 0.025\n",
    "    shift = 0.01\n",
    "    \n",
    "    # Translating into number of samples from given Hamming window particulars\n",
    "    frame_length, frame_step = int(window * sample_rate), int(shift * sample_rate)\n",
    "    signal_length = len(data)\n",
    "\n",
    "    # Calculating number of frames. Converting to inn tas the values are floats and the calculated values need to be discrete integers.\n",
    "    num_frames = int((signal_length - frame_length) / frame_step)\n",
    "\n",
    "    # Creating an envelope of array that shifts with Hamming window \n",
    "    envelope_length = num_frames * num_frames + frame_length\n",
    "\n",
    "    # Storing data into a temporary array, to be used for appending\n",
    "    temp = np.zeros((envelope_length - signal_length))\n",
    "    envelope = np.append(data, temp) \n",
    "\n",
    "    # Using np.tile to create repeating arrays while using arange to set-up frame length and corresponding entries\n",
    "    storage = np.tile(np.arange(0, frame_length), (num_frames, 1)) + np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "\n",
    "    # Storing the data into the frames\n",
    "    frames = envelope[storage]\n",
    "    \n",
    "    point_FFT = 256\n",
    "\n",
    "    fft_data = np.absolute(np.fft.fft(frames, point_FFT))  # Magnitude of the FFT\n",
    "    \n",
    "    fft_data = fft_data.T\n",
    "    \n",
    "    fft_data = fft_data[0:128,:] # Slicing into top 128 vectors \n",
    "    \n",
    "    spectrogram = fft_data.T - np.mean(fft_data.T, axis=0)\n",
    "\n",
    "    spectrogram = spectrogram.T\n",
    "    \n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8373de",
   "metadata": {},
   "source": [
    "# Function to input the spectrogram and return the transform matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e7a1cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(spectrogram):\n",
    "    \n",
    "    # Creating the covariance matrix\n",
    "    xcov = spectrogram@spectrogram.T\n",
    "\n",
    "    eigval, eigvec = linalg.eigh(xcov) # Gives eigen decomposition in ascending form\n",
    "\n",
    "    # Computing lambda^(-1/2)\n",
    "    eigval_matrix = np.diag(1/(eigval**0.5))\n",
    "\n",
    "    transform_matrix = (np.dot(eigval_matrix, eigvec.T))\n",
    "    \n",
    "    return transform_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33de4c70",
   "metadata": {},
   "source": [
    "# Function to apply it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651c8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_whitening_to_get_avg(transform_from, transform_to):\n",
    "    \n",
    "    path_of_from = 'Data/speechFiles/'+transform_from+'.wav'\n",
    "    \n",
    "    transform_matrix = transform(spectrogram(path_of_from))\n",
    "    \n",
    "    path_of_to = 'Data/speechFiles/'+transform_to+'.wav'\n",
    "    \n",
    "    y = transform_matrix@spectrogram(path_of_to)\n",
    "    \n",
    "    cov = (y@y.T)/(y.shape[1])\n",
    "    \n",
    "    cov = np.absolute(cov)\n",
    "    \n",
    "    return (np.sum(cov) - np.trace(cov))/((cov.shape[0]*cov.shape[1])-cov.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc4920e",
   "metadata": {},
   "source": [
    "To get avg of absolute values of the non diagonal values, entered in string form first the data from which the transform\n",
    "has to be derived and then in string for the data to which the transform has to be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62aba542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.982378518944804e-16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_whitening_to_get_avg('clean', 'clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9315b7",
   "metadata": {},
   "source": [
    "As expected, applying whitening to clean data from transform learnt from clean data gives almost zero value. This shows that the co-variance between clean file features is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12affb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12407493705300103"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_whitening_to_get_avg('clean', 'noisy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f319b4",
   "metadata": {},
   "source": [
    "Applying whitening to noisy data from transform learnt from clean matrix gives a considerable magnitude non-zero value. This shows that the co-variance between noisy file features with respect to clean files is tangible, but not very high. This means that there is decent amount of noise in the audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bc0a07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.330518397637393e-18"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_whitening_to_get_avg('noisy', 'noisy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bbbec2",
   "metadata": {},
   "source": [
    "As expected, applying whitening to noisy data from transform learnt from noisy data gives almost zero value. This shows that the co-variance between noisy file features is closer to zero than that with the clean files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df17ef86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00017047872267251726"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_whitening_to_get_avg('noisy', 'clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2269cab1",
   "metadata": {},
   "source": [
    "Applying whitening to clean data from the transform learnt through noisy data gives a very little covariance value between features. This shows that noisy features are closer to clean features when compared to the vice versa condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7096895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
